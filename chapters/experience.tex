\chapter{Progetto}
\label{cha:experience}

\section{Ontopic}
\label{sec:ontopic}
Il tirocinio da me svolto è avvenuto presso l'azienda Ontopic s.r.l. Tale azienda è nata nel 2019 come spin-off della Libera Università di Bolzano dal prof. Diego Calvanese insieme al professore Marco Montali, i ricercatori Guohui Xiao e Benjamin Cogrel 
e l’amministratore delegato Peter Hopfgartner presso il NOI Techpark di Bolzano\cite{Ontopic}.

L'azienda nasce con lo scopo di proporre soluzioni di data integration ed in particolare basate sull'integrazione semantica come i Virtual Knowledge Graph. Ontopic fornisce sia consulenza diretta ad aziende con soluzioni ad-hoc
per integrazione ed analisi dati che una soluzione proprietaria per il mapping di VKG chiamata Ontopic Studio. Questo applicativo è basato sul Knowledge Graph system Ontop, di cui Ontopic è uno dei principali contributori, e permette di realizzare mapping 
in modo efficiente tramite un interfaccia grafica no-code semplice che ne permette quindi l'uso anche a persone senza un background in tecniche semantiche. \cite{OntopicStudio}    

\section{Il modulo bi-connector}
\label{sec:bi-connector}
Durante la mia esperienza di tirocinio presso Ontopic, ho lavorato all'interno del progetto del bi-connector. Tale modulo ha lo scopo di permettere all'utente finale di ricavare informazioni su un VKG non solo tramite query SPARQL, come di consuetudine, ma anche
tramite strumenti di Business Intelligence (BI) come Tableau, PowerBi o Qlik. 
Mentre questi applicativi presentano nativamente connettori verso molteplici fonti di dati tra cui: la maggior parte dei database relazionali, database NoSQL come MongoDB, fogli Excel, 
dati in formato JSON, file PDF, connessioni personalizzate tramite JDBC o ODBC, \dots, non forniscono invece connettori nativi per i VKG ed è proprio per questo che nasce bi-connector.

\begin{comment}{}
    In particolare, il primo applicativo di business intelligence su quale si è focalizzato lo sforzo di sviluppo è stato Tableau e perciò nel resto dell'elaborato farò principalmente riferimento a questo.
\end{comment}
Possiamo pensare a bi-connector come costituito di due parti principali: una che si occupa della costruzione di un database a partire dall'ontologia che possa essere connesso al strumento di BI target e una seconda parte che ha il compito di tradurre le query 
SQL sul database in una forma comprensibile dal VKG sottostante.

\subsection{Creazione database}
\label{sec:bi-connector_db}
Dalle sorgenti di dati e dai file che utilizzati per creare i mapping di un VKG viene creato un database PostgreSQL.
Questo è reso possibile modificando direttamente i cataloghi di sistema resi disponibili da PostgreSQL tramite l'insieme di tabelle \textit{pg\_catalog}.

Da estendere chiedendo a Benjamin

\subsection{Parsing di query SQL}
\label{sec:bi-connector_parsing}
\`E possibile interrogare il database inizialmente creato tramite query SQL, ma queste devono poi essere tradotte in una rappresentazione comprensibile dal VKG sottostante. Questo perché le query non sono eseguite sul database da noi creato, ma sul
Virtual Knowledge Graph originale così da poterne sfruttare le capacità di inferenza.

In quanto il VKG system utilizzato è Ontop, le query SQL vengono tradotte in un albero IQ, descritto precedentemente anche nella sezione \ref{sec:ontop_iq}. 

Inizialmente, le query delle quali era possibile fare il parsing erano del tipo SELECT-JOIN-WHERE, ovvero un'unione di query congiuntive. Questo era dovuto al fatto che il parser SQL in uso fosse quello nativo di Ontop,
il quale ha come scopo principale la traduzione dei mapping che sono, nella maggior parte dei casi, rappresentabili tramite query semplici.
A causa di questa limitazione moltissime delle query usate per la costruzione del database, che modificano direttamente i cataloghi di sistema di PostgreSQL, erano semplificate in modo da poter essere usate, ma questo le rendeva solo parzialmente
corrette. Un esempio di ciò:
\begin{lstlisting}
    SELECT n.oid, n.*, d.description 
    FROM pg_catalog.pg_namespace n
    LEFT OUTER JOIN pg_catalog.pg_description d ON d.objoid=n.oid 
        AND d.objsubid=0 AND d.classoid='pg_namespace'::regclass
    ORDER BY nspname
    diventa:
    SELECT n.* 
    FROM pg_catalog.pg_namespace n;
\end{lstlisting}
Si può vedere come la query sia semplificata eliminando il LEFT JOIN e l'ORDER BY in quanto non supportati.

\begin{comment}
    SELECT t.oid, t.*
    FROM pg_catalog.pg_tablespace t
    "ORDER BY t.oid";
    becomes:
    SELECT t.*
    FROM pg_catalog.pg_tablespace t;
\end{comment}
Date queste limitazioni del parser originale, si è deciso di adottarne uno diverso ovvero JSqlParser. JSqlParser è un parser di istruzioni SQL
che trasforma una query in una gerarchia di classi Java. \`E basato sul visitor pattern il quale permette di separare in modo semplice un algoritmo dalla struttura dati sulla quale è utilizzato. 
In particolare tale pattern rappresenta un'operazione che deve essere eseguita su un insieme eterogeneo di oggetti e, per ognuno di questi, potrebbe dover essere implementata in modo differente \cite{JSqlParser}.

\section{Prime attività}
\label{sec:prerequisits}
La prima attività svolta all'interno del tirocinio è stata quella di svolgere il tutorial introduttivo ad Ontop tramite la piattaforma Protege in modo da poter familiarizzare con 
che cosa sia un Virtual Knowledge Graph, quali siano le sue componenti ed in particolare come i mapping vengono scritti e tradotti.

Analisi di quali fossero i costrutti usati nelle query automaticamente generate da Tableau (ad esempio viene usato moltissimo il GROUP BY) e analisi di quale fosse il comportamento specifico di PostgreSQL su queste keyword
(e.g. in PostgreSQL la funzione CONCAT non è null-rejecting, MINUS non è supportato, tipo di NULL ordering di default, \dots)

Strumenti utilizzanti: db su cui ho svolto tutti i test (ProfJDBC), DBeaver per la visualizzazione db, BDFiddle (keyword explain) e documentazione PG per testare i diversi comportamenti delle keyword


\section{Costrutti implementati}
\label{sec:implementation}

\subsection{Distinct, Limit e Offset}

Distinct implementato tramite un semplice IQ node Distinct
Limit e Offset implementati con un filtro
Interessanti principalmente in quanto sono stati un primo approccio sia alle struttura generale del progetto / IQTree che a JSqlParser più che come funzionalità complesse da implementare.

\subsection{Ordinamento righe}
Order by più complesso in quanto richiede la creazione di comparatori, operazioni di sostituzione per la proiezione delle variabili 
e la gestione del NULL ordering.

\subsection{Combinazione tabelle}
Cross e inner join già presenti, implementazione left join (scontato di conseguenza il right join) 
Problematiche sorte su colonne con stessi nomi

\subsection{Operazioni insiemistiche}
Operazioni su insiemi (unione e sottrazione) implementate con alcune restrizioni.
L'implementazione della sottrazione è interessante (implementata come filtro su un left join).

\subsection{Aggregazione}
Funzioni di aggregazione (SUM, COUNT, MIN, MAX, AVG) per cui è stato necessario introdurre una funzionalità che ritardasse l'assegnazione del 
tipo alla funzione. (Questo perché SPARQL a differenza di SQL usa una tipizzazione dinamica).
Costrutto Group by e having (interessante l'implementazione per funzioni con la sostituzione dei functional term con variabili)

\section{Risultati ottenuti}
Con l'introduzione dell'aggregazione (e anche dell'order by) è stato possibile rimuovere buona parte delle query automaticamente create da Tableau --> accesso a Tableau 
e prime dashboard create su dataset non banali (chiedere a Benjamin se ha qualche screenshot)
